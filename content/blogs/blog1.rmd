---
categories:
- ""
- ""
date: "2017-10-31T21:28:43-05:00"
description: ""
draft: false
image: pic10.jpg
keywords: ""
slug: ipsum
title: Ipsum
---



```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(infer)
library(scales)
library(RColorBrewer)
library(knitr)
library(kableExtra)
library(countrycode)
```



Recall the TfL data on how many bikes were hired every single day. We can get the latest data by running the following

```{r, get_tfl_data, cache=TRUE}
url <- "https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx"

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp <- tempfile(fileext = ".xlsx")))

# Use read_excel to read it as dataframe
bike0 <- read_excel(bike.temp,
                   sheet = "Data",
                   range = cell_cols("A:B"))

# change dates to get year, month, and week
bike <- bike0 %>% 
  clean_names() %>% 
  rename (bikes_hired = number_of_bicycle_hires) %>% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))
```



It is pretty easy to make a graph like the one below:

```{r tfl_month_year_grid, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "tfl_distributions_monthly.png"), error = FALSE)
```

We just run this code:

```{r tfl_month_year_grid_reproduced}

bike_1520 <- bike %>% 
  filter(year >= 2015) 

# Creates function for number format on x-axis
ks <- function (x) { number_format(accuracy = 1,
                                   scale = 1/1000,
                                   suffix = "k",
                                   big.mark = ",")(x) }

ggplot(bike_1520, aes(x = bikes_hired))+
  geom_density()+
  # Splits into grid with years as rows and months as columns
  facet_grid(rows = vars(year), cols = vars(month))+
  theme_minimal()+
  labs(title = "Distribution of bikes hired per month",
       x = "Bike Rentals",
       y = "")+
  theme(axis.text  = element_text(size = 6),
        axis.text.y = element_blank())+
  scale_x_continuous(labels = ks)

```

If we look at May and June in 2020 relative to the other years we see the standard deviation is higher and the distribution is slightly skewed to the left. Obviously this is because of COVID, where the lockdown have resulted in fewer rentals.


This was fairly simple, but let us work on something a bit harder and try to replicate these graphs:

```{r tfl_absolute_monthly_change, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "tfl_monthly.png"), error = FALSE)
```

This first one has four graphic elements we have to take into account

* Monthly average calculated throughout the period - this is constant for each month throughout the periods - let us call it mean_bike

* The actual mean value for each month and year, let is call it bikes_hired_mth

* The area between the two values, where mean_bike is greater than bikes_hired_mth, which is colored red

* The area between the two values, where mean_bike is less than bikes_hired_mth, which is colored green

To achieve this, we first calculate the two variables, mean_bikes and bikes_hired_mth, then we create a plot with two lines based on the two variables using geom_line, and then we color the two areas using geom_ribbon.

```{r monthly bike rental}
# First we find the average for each month throughout the whole period
bike_avg <- bike %>% 
  filter(year %in% c(2015:2019)) %>% 
  group_by(month) %>% 
  summarize(mean_bike = mean(bikes_hired)) 

# Now we then find the average for each month
bike_ribbon <- bike %>% 
  filter(year >= 2015,
         day < "2020-08-01") %>% 
  group_by(month, year) %>% 
  summarize(bikes_hired_mth = mean(bikes_hired)) %>%
  # We then join the two data tables
  left_join(y = bike_avg, join_by =  month) 

#Now we then recreate the graph

ggplot(bike_ribbon, aes(x = month, 
                        y = mean_bike,
                        group = 1))+
  # We split the plot into 5 graphs - one for each year  
  facet_wrap(~year)+
  # We create two lines, one for the mean bikes hired per month over the whole period and one for the year in question
  geom_line(aes(y = mean_bike), color = "Dark Blue")+
  geom_line(aes(y = bikes_hired_mth), color = "Black")+
  # We then create two ribbons. The first colors the area at which mean_bike > bikes_hired_mth red, while the second colors the area where mean_bike > bikes_hired_mth green
  geom_ribbon(aes(ymin = mean_bike, 
                  ymax = pmin(mean_bike, bikes_hired_mth)), 
              fill = "Red",
              alpha = 0.2)+
  geom_ribbon(aes(ymin = bikes_hired_mth, 
                  ymax = pmin(mean_bike, bikes_hired_mth)),
              fill = "Green",
              alpha = 0.2)+
 # We finally add titles and change the aesthetics of the graph
  labs(title = "Monthly changes in TfL bike rentals",
       subtitle = "Change from monthly average shown in blue \nand calculated between 2015 and 2019",
       x = "",
       y = "Bike rentals",
       caption = "Source: TfL, London Data Store")+
  theme_minimal()
  




```


The second one looks at percentage changes from the expected level of weekly rentals. The two grey shaded rectangles correspond to the second (weeks 14-26) and fourth (weeks 40-52) quarters.

```{r tfl_percent_change, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "tfl_weekly.png"), error = FALSE)
```

Again we here have a couple of elements. Firstly there is the tick marks with a green/red color depending on whether the week is positive or negative. Then we have the line that shows the deviation from the expected value. Thirdly, we have the area between the 0 and the line of the actual weekly value, which is colored depending on whether it is positive or negative. Finally we have the background color that shows quarters.

Let us try to solve this challenge step by step

```{r weekly bike rental}
# As before we start by creating a dataframe with the average values weekly rental values throughout 2015-2019
bike_avg_wk <- bike %>% 
  filter(year %in% c(2015:2019)) %>% 
  group_by(week) %>% 
  summarize(mean_bike_wk = mean(bikes_hired)) 

# We then find the actual weekly values for each week each year and join the data table we created before
bike_ribbon_wk <- bike %>% 
  filter(year >= 2015,
         day < "2020-08-01") %>% 
  group_by(week, year) %>% 
  summarize(bikes_hired_wk = mean(bikes_hired)) %>%
  left_join(y = bike_avg_wk, join_by =  week) %>% 
  # Finally we calculate the difference from the weekly change in a new column
  mutate(deltapct_bike_wk = (bikes_hired_wk - mean_bike_wk) / mean_bike_wk)



# We now create the graph
ggplot(bike_ribbon_wk, aes(x = week,
                           y = deltapct_bike_wk))+
  facet_wrap(~year)+
  # We add the line showing development during the year
  geom_line()+
  # We use two geom_ribbon to color the area above and below the line. We use the delta as one argument and 0 as the other, as if the actual value = expected value, we would have a delta of 0.
  geom_ribbon(aes(ymin = 0, 
                  ymax = pmin(deltapct_bike_wk, 0)), 
              fill = "Red",
              alpha = 0.3)+
  geom_ribbon(aes(ymin = deltapct_bike_wk, 
                  ymax = pmin(deltapct_bike_wk, 0)),
              fill = "Green",
              alpha = 0.3)+
  # We then add the rectangular fills for the different quarters - first we define the areas we want colored and then we define the colors used
  geom_tile(aes(fill = week %in% c(14:26, 40:53)),
            width = 1,
            height = Inf,
            alpha = 0.25,
            show.legend = FALSE)+
  scale_fill_manual(values = c("white", "gray"))+
  #Now we add the tick marks and color them
  geom_rug(sides = "b", 
           aes(color = ifelse(deltapct_bike_wk > 0, "Above", "Below")),
           show.legend = FALSE)+
  scale_colour_manual(values = c("#7DCD85", "#CB454A"), guide = FALSE)+
   # Finally we fix the aesthetics of the graph
  scale_y_continuous(labels = percent)+
  scale_x_continuous(breaks = c(13, 26, 39, 53))+
  labs(title = "Weekly changes in TfL bike rentals",
       subtitle = "Change from weekly averages  \ncalculated between 2015 and 2019",
       x = "Week",
       y = "",
       caption = "Source: TfL, London Data Store")+
  theme_minimal()

```

Here we have used mean instead of median. When deciding on this the main consideration to take into account is how the difference is between the weekend and the week. Intuitively, we would expect every weekday to have fairly similar rental numbers, while the weekends would be either significantly higher or lower. When using median, this would not be taken into account, as one would most likely end with a weekday value (as there are five of them and they are similar). We have therefore included the mean, as we would like to take the weekend number deviations into account.